# Логика прогрессии и работы ИИ

Документ описывает, как бот анализирует выполненные тренировки, обновляет прогрессии упражнений и использует историю, чтобы формировать персональные рекомендации. Правила диалогового поведения и протоколы безопасности вынесены в отдельный файл [«Правила поведения и интентов ИИ-тренера»](pravila-ii-i-dialoga.md).

## Термины
- **Уровень упражнения** — целевые подходы и повторения, необходимые для перехода к следующей стадии развития навыка.
- **Прогрессия** — последовательность уровней для одного упражнения. Может быть линейной (фиксированные ступени) или гибкой (есть базовые правила увеличения нагрузки без строгих уровней).
- **Сессия** — тренировка в конкретный день с перечнем упражнений, подходов, повторений, субъективных оценок (RPE) и заметок.
- **История** — агрегированная информация о последних N (по умолчанию 10) сессиях: достигнутые уровни, пропуски, усталость, рекорды.

## Общий поток данных прогрессии
1. Пользователь выполняет тренировку и отправляет отчёт `/report`.
2. Бот сохраняет сырые данные по каждому упражнению: фактические подходы/повторы, комментарии, RPE, отметки о самочувствии.
3. Модуль анализа прогрессии сравнивает факт выполнения с целевыми параметрами текущего уровня.
4. На основе правил перехода определяется, стоит ли продвинуть уровень, закрепить его или сделать шаг назад.
5. Решение записывается в Supabase и передаётся планировщику (ChatGPT) при генерации следующего плана.

## Правила оценки выполнения
### Упражнения с фиксированными уровнями
- **Успех**: выполнено ≥ 105% целевого объёма и RPE ≤ 7. Результат — продвижение на следующий уровень.
- **Закрепление**: выполнено от 90% до 105% целевого объёма или RPE 8–9. Результат — повторить уровень на следующей тренировке.
- **Откат**: выполнено < 90% целевого объёма, RPE ≥ 10 или отметка о боли. Результат — вернуться на предыдущий уровень или снизить объём на 10–20%.

#### Типы упражнений
- **Силовые** (подтягивания, отжимания, приседания): шаг по уровню = +1 подход или +2 повторения; допустимая скорость роста — не чаще чем через две успешные сессии.
- **Выносливость** (планка, кардио-блоки): шаг = +10% времени/объёма, условие продвижения — RPE ≤ 6 дважды подряд.
- **Мобилизация** (мостик, растяжка): шаг = увеличение амплитуды или сложности вариации, RPE не применяется — прогресс оценивается по субъективной шкале комфорта (0–5).

### Упражнения без уровней
- Хранится целевой диапазон повторений и подходов (например, 3×8–12).
- При превышении верхней границы диапазона три сессии подряд бот увеличивает нагрузку: добавляет подход, усложняет вариацию или советует утяжеление.
- При систематическом недовыполнении бот предлагает облегчённую вариацию, уменьшает объём или добавляет подсказки по технике.
- Для смешанных сессий (сочетание фиксированных и гибких прогрессий) распределение адаптации следующее: сначала корректируется гибкая часть (±1 подход/повтор), затем при стабильности меняется фиксированный уровень.

### Дополнительные факторы
- **Пропуски**: если упражнение пропущено больше одного раза подряд, уровень не повышается до двух стабильных выполнений.
- **Техника**: при отметке «проблема с техникой» прогрессия замораживается, добавляются вспомогательные упражнения или ссылки на обучающие материалы.

## Обновление планов
1. После анализа прогрессии формируется объект `progress_update` с решением (перейти, закрепить, откатить), новым целевым уровнем и комментариями.
2. Edge Function `update_plan` формирует системный промпт для ChatGPT с краткой сводкой по упражнению, решением алгоритма и ограничениями (доступное оборудование, расписание, усталость).
3. ChatGPT возвращает обновлённый план. Бот сохраняет его в Supabase и отправляет пользователю сводку с пояснениями.

## Использование истории ИИ
- История хранится в таблицах `training_sessions` и `exercise_progress`.
- `exercise_progress` включает поля: `session_id`, `exercise_key`, `level_target`, `level_result`, `volume_target`, `volume_actual`, `rpe`, `notes`, `decision`, `streak_success`.
- При генерации плана ChatGPT получает компактную сводку: текущий уровень, результаты трёх последних сессий, тенденция по RPE, наличие пропусков.
- Для еженедельных и ежемесячных отчётов строятся тренды по объёму, прогрессу уровней и субъективной нагрузке.
- **Хранение и очистка**: записи `exercise_progress` старше 18 месяцев архивируются в таблицу `exercise_progress_archive`, а агрегированные метрики (`rolling_volume`, `rolling_rpe`) пересчитываются раз в неделю. Очистка запускается Edge Function `archive_progress` по расписанию (воскресенье 23:00).
- **Лимиты хранения**: если число записей на пользователя > 10 000, архивирование запускается вне расписания, а бот уведомляет о возможной задержке аналитики.

## Логика рекомендаций на следующую тренировку
| Сценарий | Поведение бота |
| --- | --- |
| Перевыполнение без высокой усталости | Предложить следующий уровень, добавить мотивационное сообщение |
| Выполнение на грани | Предложить выбор: повторить уровень или попробовать следующий с предупреждением |
| Недовыполнение | Указать, сколько повторений/подходов не хватило, предложить облегчённую вариацию |
| Слишком высокое RPE | Снизить объём на 10–15%, добавить рекомендации по восстановлению |
| Пропуск | Напомнить о регулярности, предложить вернуться к предыдущему уровню |

## Интеграция с диалогами
- Системный промпт ChatGPT содержит инструкцию использовать историю прогрессии, упоминать конкретные уровни и объёмы, предлагать варианты адаптации.
- Сообщения пользователя анализируются на признаки усталости или боли; при их наличии ставится флаг `fatigue_flag`, который влияет на следующий ответ и план.
- Контекст последнего диалога сохраняется в таблице `dialog_context`, чтобы после перезапуска бота продолжать разговор с учётом предыдущих рекомендаций.
- При ручной коррекции (пользователь просит «убери последние подходы») запись помечается флагом `manual_override`. Алгоритм приоритетов: `manual_override` > автоматическое решение прогрессии > дефолтное значение плана. Каждая правка логируется в `plan_version_audit` с указанием автора и причины.
- Конфликты между ручным и автоматическим решением решаются следующим образом:
  1. Если ручная правка и автоматическое решение произошли в течение 24 часов — приоритет за ручной правкой, автоматическое решение откладывается на следующую сессию.
  2. Если ручная правка старше 24 часов, а новая аналитика противоречит ей, бот запрашивает подтверждение и предлагает компромисс (среднее значение нагрузки).
  3. Все нерешённые конфликты отображаются в еженедельном обзоре с предложением принять одно из решений.

## Примеры расчётов на данных
- **Подтягивания уровень 3**: целевой объём 4×6 (24 повтора). Факт — 4×7 (28 повторов), RPE 6. Алгоритм: 28 ≥ 24 × 1.05 → продвижение на уровень 4 (5×6), `decision = advance`, `streak_success = 1`.
- **Отжимания на брусьях уровень 2**: целевой объём 3×10 (30 повторов). Факт — 3×9, RPE 9. 27 находится в диапазоне [27, 31.5], но RPE 9 ⇒ закрепление. `decision = hold`, комментарий «держим уровень из-за высокой нагрузки».
- **Планка 3 минуты**: целевой объём 180 секунд, факт — 150 секунд, RPE 8, отметка «усталость». Недовыполнение 150 < 180 × 0.9 ⇒ `decision = regress`, новая цель 150 секунд, рекомендована вариация с колен.
- **Смешанная сессия**: упражнение с диапазоном 8–12 повторов. Последние три сессии: 12, 12, 13 повторов. Алгоритм фиксирует превышение и предлагает добавить 1 подход или утяжеление +2 кг.
- **Пропуск**: две пропущенные записи подряд (`status = skipped`). Алгоритм удерживает уровень и добавляет в план «разминочную» сессию с снижением объёма на 30%.

## Согласование с `plan_versions`
- **Запись решений**: после расчёта `decision` формируется запись в `plan_version_items` с типом события `auto_adjustment` и ссылкой на `exercise_progress.id`. Это позволяет отследить, какие упражнения были изменены алгоритмом.
- **Версионирование**: при каждом продвижении уровня создаётся новая версия плана (`plan_versions.version + 1`), содержащая только изменённые упражнения. Поле `summary` заполняется структурой `{ "exercise": "pull_up", "change": "advance", "reason": "low_rpe" }`.
- **Конфликты**: если за день сформировано >1 версии (например, ручная правка + автоматическое обновление), создаётся запись в `plan_version_conflicts` с полями `profile_id`, `date`, `auto_version`, `manual_version`, `status`. Edge Function проверяет таблицу перед активацией версии и при необходимости ставит статус `pending_confirmation`.
- **Ручной откат**: при команде «откатить понедельник» алгоритм выполняет выборку активной версии по `slot_date`, переносит в новую версию значения `level_target`/`volume_target` из предыдущей (`version - 1`) и помечает исходную версию как `superseded`.
- **Сессии в один день**: если пользователь выполняет две тренировки в день, `plan_version_items` фиксирует `slot_time` (утро/вечер). В случае конфликтов решения объединяются: приоритет получает запись с более поздним временем создания.

## Мониторинг качества прогрессий
- **Метрики**: `progression_accuracy` (доля успешных выполнений после повышения уровня), `regression_rate`, `fatigue_alerts`, `manual_override_rate`. Значения хранятся в `metrics` с `metric_type` = `progression_*` и датой отчёта.
- **Алерты**: Grafana алерт, если `regression_rate` > 25% три дня подряд или `fatigue_alerts` растёт > 15% неделя к неделе. При срабатывании бот отправляет заметку «Похоже, нагрузка стала излишней, проверь восстановление».
- **Логи**: таблица `progression_events` содержит события `decision_made`, `decision_overridden`, `alert_triggered` с полями `exercise_key`, `decision`, `source`, `trace_id`. Хранение — 6 месяцев.
- **Ручная проверка**: раз в неделю формируется отчёт для ревью (CSV/Google Sheet) с упражнениями, где три отката подряд. В процессе ревью отмечается `verified = true/false`, после чего алгоритм либо продолжает автоматические действия, либо замораживает упражнение (`suspension_flag = true`).
- **Тестовые наборы**: перед выкладкой изменений прогрессии запускается симуляция на исторических данных за последние 90 дней. Критерии: `progression_accuracy` ≥ 70%, количество `manual_override` не увеличивается > 5%.

## Псевдокод анализа прогрессии
```pseudo
for exercise in session.exercises:
  baseline = get_current_level(exercise)
  target_volume = baseline.sets * baseline.reps
  actual_volume = exercise.completed_sets * exercise.completed_reps
  effort = exercise.rpe

  if exercise.skipped:
    decision = 'hold'
  else if actual_volume >= target_volume * 1.05 and effort <= 7:
    decision = 'advance'
  else if actual_volume >= target_volume * 0.9 and effort <= 9:
    decision = 'hold'
  else:
    decision = 'regress'

  decision = adjust_for_history(decision, history_streaks, fatigue_flags)
  save_progress(exercise, decision)
```

## План расширения
- Добавить адаптивный коэффициент сложности на основе динамики RPE: при стабильном снижении RPE повышать целевой объём.
- Реализовать модель прогнозирования недовыполнений (например, градиентный бустинг по истории), чтобы корректировать план заранее.
- Включить рекомендации по восстановлению (сон, питание) при частом высоком RPE или отметках о боли.
- Создать визуализации прогрессии (графики) в еженедельных и ежемесячных отчётах.
